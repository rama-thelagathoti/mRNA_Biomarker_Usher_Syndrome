{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9452fd10-ecee-4597-a16e-9a2a4b5b64f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, RFE, VarianceThreshold, SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, LassoCV\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix, roc_curve\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38aaef8a-49d6-4abb-a49b-a4f5145e4631",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ignore warningsa\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1175c201-85df-438b-b0ff-fda87925762a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    df = pd.read_csv('data/new_map.csv', header = 0)\n",
    "    df.set_index(df.columns[0], inplace=True)\n",
    "    df.rename_axis(\"ID\", inplace=True)\n",
    "    \n",
    "    meta = pd.read_csv('data/samples_wo_UT.csv', header = 0)\n",
    "\n",
    "    print(df.shape)\n",
    "    print(meta.shape)\n",
    "    \n",
    "    mdf = pd.merge(df, meta, on='ID')\n",
    "    \n",
    "    print(mdf.shape)\n",
    "    \n",
    "    return mdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a397124e-7107-40d3-82c6-2a014d5ef80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, *cols_to_exclude):\n",
    "    df_copy = df.copy()\n",
    "    cols_to_exclude = list(cols_to_exclude)\n",
    "    cols_to_scale = [col for col in df.columns if col not in cols_to_exclude]\n",
    "    scaler = MinMaxScaler()\n",
    "    df_copy[cols_to_scale] = scaler.fit_transform(df_copy[cols_to_scale])       \n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aed3bce-150b-43f8-92fa-0ecf1661c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "df = df.drop(['ID'],axis = 1)\n",
    "df = df.drop(['path', 'group', 'name','phenotype', 'genotype', 'cell', 'status',],axis=1)\n",
    "x_train = preprocess(df,'target0')\n",
    "y_train = df['target0']\n",
    "x_train = x_train.drop('target0',axis = 1)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "X = x_train\n",
    "y = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49d7f76-181f-4b6a-b064-02deb73661c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature selection method\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.utils import resample\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "from scipy.stats import spearmanr\n",
    "from itertools import combinations\n",
    "\n",
    "# Try with random features\n",
    "# Example: Replace this with actual data loading\n",
    "# X = <your_features>\n",
    "# y = <your_labels>\n",
    "#X = np.random.rand(32, 40000)  # Placeholder dataset with 32 samples and 40000 features\n",
    "#y = np.random.randint(0, 2, 32)  # Placeholder binary labels\n",
    "\n",
    "df = load_data()\n",
    "df = df.drop(['ID'],axis = 1)\n",
    "df = df.drop(['path', 'group', 'name','phenotype', 'genotype', 'cell', 'status',],axis=1)\n",
    "x_train = preprocess(df,'target0')\n",
    "y_train = df['target0']\n",
    "x_train = df.drop('target0',axis = 1)\n",
    "print(f'shape 1 {x_train.shape}')\n",
    "print(y_train.shape)\n",
    "X = x_train\n",
    "y = y_train\n",
    "\n",
    "# Check for class imbalance\n",
    "print(f\"Original class distribution: {Counter(y)}\")\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', use_label_encoder=False),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "}\n",
    "\n",
    "# Scaling features\n",
    "#scaler = StandardScaler()\n",
    "#X = scaler.fit_transform(X)\n",
    "\n",
    "#X = pd.DataFrame(X)\n",
    "# Stratified K-Fold Cross Validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Feature Selection and Model Evaluation\n",
    "results = {model_name: [] for model_name in models.keys()}\n",
    "final_feature_names = []\n",
    "common_features = None\n",
    "feature_rankings = []\n",
    "selected_features_list = []\n",
    "\n",
    "for train_idx, test_idx in skf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # Apply SMOTE for oversampling the minority class\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    print(f\"Class distribution after SMOTE: {Counter(y_train)}\")\n",
    "\n",
    "    # Stage 1: Variance Threshold\n",
    "    selector = VarianceThreshold(threshold=0.01)\n",
    "    X_train = selector.fit_transform(X_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "    feature_names = X.columns[selector.get_support()]\n",
    "    print(f\"Stage 1 - Variance Threshold: {len(feature_names)} features selected\")\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    \n",
    "    # Stage 2: Univariate Feature Selection (ANOVA F-test)\n",
    "    selector = SelectKBest(score_func=f_classif, k=5000)  # Select top 2000 features\n",
    "    X_train = selector.fit_transform(X_train, y_train)\n",
    "    X_test = selector.transform(X_test)\n",
    "    feature_names = feature_names[selector.get_support()]\n",
    "    print(f\"Stage 2 - SelectKBest: {len(feature_names)} features selected\")\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "\n",
    "    # Stage 3: Recursive Feature Elimination with Random Forest\n",
    "    rfc = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "    rfc.fit(X_train, y_train)\n",
    "    importances = rfc.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1][:1000]  # Select top 500 features\n",
    "    X_train = X_train[:, indices]\n",
    "    X_test = X_test[:, indices]\n",
    "    feature_names = feature_names[indices]\n",
    "    print(f\"Stage 3 - Recursive Feature Elimination: {len(feature_names)} features selected\")\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "\n",
    "    # Stage 4: Final Feature Reduction (Top 100 features using Lasso)\n",
    "    lasso = Lasso(alpha=0.05, max_iter=1000)\n",
    "    lasso.fit(X_train, y_train)\n",
    "    lasso_mask = np.argsort(np.abs(lasso.coef_))[::-1][:500]  # Indices of top 100 features\n",
    "    X_train = X_train[:, lasso_mask]\n",
    "    X_test = X_test[:, lasso_mask]\n",
    "    final_feature_names = feature_names[lasso_mask]\n",
    "\n",
    "    feature_rankings.append(final_feature_names)\n",
    "    selected_features_list.append(set(final_feature_names))\n",
    "\n",
    "    #print(f\"Stage 4 - Final Feature Set: {len(final_feature_names)} features selected\")\n",
    "    print(X_train.shape)\n",
    "    print(X_test.shape)\n",
    "    #final_feature_names = feature_names\n",
    "    #print(f'Final features list {final_feature_names.tolist()}')\n",
    "  #  # Stage 4: Final Feature Reduction (Top 100 features)\n",
    "  #  X_train = X_train[:, :100]\n",
    "  #  X_test = X_test[:, :100]\n",
    "  #  final_feature_names = feature_names[:100]\n",
    "  #  print(f\"Stage 4 - Final Feature Set: {len(final_feature_names)} features selected\")\n",
    "    # Track features across folds\n",
    "    if common_features is None:\n",
    "        common_features = set(final_feature_names)\n",
    "    else:\n",
    "        common_features.intersection_update(final_feature_names)\n",
    "  \n",
    "    # Bootstrapping for Model Evaluation\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Performance Metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        sensitivity = recall_score(y_test, y_pred)\n",
    "        specificity = recall_score(y_test, y_pred, pos_label=0)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "        results[model_name].append({\n",
    "            \"accuracy\": accuracy,\n",
    "            \"sensitivity\": sensitivity,\n",
    "            \"specificity\": specificity,\n",
    "            \"f1_score\": f1,\n",
    "            \"auc\": roc_auc,\n",
    "        })\n",
    "\n",
    "# Compute Spearman Rank Stability\n",
    "all_features = list(set().union(*feature_rankings))\n",
    "rank_matrices = np.zeros((len(feature_rankings), len(all_features)))\n",
    "for i, ranking in enumerate(feature_rankings):\n",
    "    for j, feature in enumerate(all_features):\n",
    "        if feature in ranking:\n",
    "            rank_matrices[i, j] = ranking.tolist().index(feature) + 1\n",
    "        else:\n",
    "            rank_matrices[i, j] = len(ranking) + 1  # Assign lowest rank if not present\n",
    "\n",
    "spearman_correlations = []\n",
    "for i in range(len(rank_matrices) - 1):\n",
    "    corr, _ = spearmanr(rank_matrices[i], rank_matrices[i + 1])\n",
    "    spearman_correlations.append(corr)\n",
    "\n",
    "mean_spearman_stability = np.mean(spearman_correlations)\n",
    "print(f\"Spearman Rank Stability: {mean_spearman_stability:.4f}\")\n",
    "\n",
    "# Summary of Results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    for metric_name in [\"accuracy\", \"sensitivity\", \"specificity\", \"f1_score\", \"auc\"]:\n",
    "        mean_metric = np.mean([m[metric_name] for m in metrics])\n",
    "        print(f\"  {metric_name}: {mean_metric:.4f}\")\n",
    "\n",
    "# Display final selected feature names\n",
    "print(\"Final Selected Features (Top 100):\", final_feature_names.tolist())\n",
    "# Output common features across all folds\n",
    "common_features = list(common_features)\n",
    "print(\"\\n--- Common Features Across All Folds ---\")\n",
    "print(common_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1fba0a-29a6-4510-98d5-e1ccd4900b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training and validation with common_features set\n",
    "\n",
    "X_features = X[common_features]\n",
    "#random_features = np.random.choice(X.columns, size=58, replace=False)\n",
    "#X_features = X[random_features]\n",
    "\n",
    "print(X_features.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Check for class imbalance\n",
    "print(f\"Original class distribution: {Counter(y)}\")\n",
    "\n",
    "# Initialize models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(eval_metric='logloss', use_label_encoder=False),\n",
    "    \"AdaBoost\": AdaBoostClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"SVM\": SVC(probability=True),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "}\n",
    "\n",
    "# Scaling features\n",
    "#scaler = StandardScaler()\n",
    "#X = scaler.fit_transform(X)\n",
    "\n",
    "#X = pd.DataFrame(X)\n",
    "# Stratified K-Fold Cross Validation\n",
    "n_splits = 5\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Feature Selection and Model Evaluation\n",
    "results = {model_name: [] for model_name in models.keys()}\n",
    "\n",
    "for train_idx, test_idx in skf.split(X_features, y):\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    # Apply SMOTE for oversampling the minority class\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "    print(f\"Class distribution after SMOTE: {Counter(y_train)}\")\n",
    "\n",
    "    # Bootstrapping for Model Evaluation\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "        # Performance Metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        sensitivity = recall_score(y_test, y_pred)\n",
    "        specificity = recall_score(y_test, y_pred, pos_label=0)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "        roc_auc = roc_auc_score(y_test, y_proba)\n",
    "\n",
    "        results[model_name].append({\n",
    "            \"accuracy\": accuracy,\n",
    "            \"sensitivity\": sensitivity,\n",
    "            \"specificity\": specificity,\n",
    "            \"f1_score\": f1,\n",
    "            \"auc\": roc_auc,\n",
    "        })\n",
    "\n",
    "\n",
    "# Summary of Results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    for metric_name in [\"accuracy\", \"sensitivity\", \"specificity\", \"f1_score\", \"auc\"]:\n",
    "        mean_metric = np.mean([m[metric_name] for m in metrics])\n",
    "        print(f\"  {metric_name}: {mean_metric:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55787470-a85c-493a-a120-a75e8de8a15a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SHAP with Naive Bayes\n",
    "import shap\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_selected = X[common_features]\n",
    "print(X_selected.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# Train-test split\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize Naïve Bayes model\n",
    "model = GaussianNB()\n",
    "\n",
    "# Train model\n",
    "model.fit(X_selected, y)\n",
    "\n",
    "# Compute SHAP values\n",
    "explainer = shap.KernelExplainer(model.predict, X_selected)\n",
    "shap_values = explainer.shap_values(X_selected)\n",
    "\n",
    "# SHAP Summary Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "shap.summary_plot(shap_values, X_selected, show=False)\n",
    "plt.title(\"SHAP Summary Plot - Naïve Bayes\")\n",
    "plt.show()\n",
    "\n",
    "shap.plots.violin(shap_values,X_selected, show=False)\n",
    "shap.summary_plot(shap_values,X_selected, show=False, plot_type=\"bar\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8965c2-0da2-4ad2-aad1-fa8a961f9644",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values,X_selected, show=False, plot_type=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6e54e2-decd-46a3-b2b5-7d9528f3b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"data/plot.csv\")  # Ensure correct formatting\n",
    "print(\"Original Data Shape:\", df.shape)\n",
    "\n",
    "# Transpose data to have mRNAs as rows and Usher/Control as columns\n",
    "df_t = df.T  # Transpose the dataframe\n",
    "df_t.columns = df_t.iloc[0]  # Set mRNA names as column headers\n",
    "df_t = df_t.iloc[1:]  # Remove the first row (old column headers)\n",
    "df_t = df_t.apply(pd.to_numeric, errors='coerce')  # Convert values to numeric\n",
    "\n",
    "#print(\"Transposed Data:\\n\", df_t)\n",
    "#print(\"Transposed Data Shape:\", df_t.shape)  # Should be (num_samples, 58)\n",
    "\n",
    "# Apply Log Transformation for better visualization\n",
    "df_t_log = np.log1p(df_t)  # log1p to prevent log(0) errors\n",
    "#print(\"Log-Transformed Data:\\n\", df_t_log)\n",
    "\n",
    "# Create Heatmap\n",
    "plt.figure(figsize=(14, 8))  # Adjusted figure size for better visualization\n",
    "ax = sns.heatmap(\n",
    "    df_t_log, \n",
    "    cmap=\"OrRd\", \n",
    "    annot=False, \n",
    "    linewidths=0.5, \n",
    "    yticklabels=True  # Ensure y-axis labels are shown\n",
    ")\n",
    "\n",
    "# Formatting\n",
    "#plt.title(\"Heatmap of Log-Scaled mRNA Expression in Usher vs. Control\", fontsize=16)\n",
    "plt.xlabel(\"mRNAs\", fontsize=12)\n",
    "plt.ylabel(\"Expression Level\", fontsize=12)\n",
    "plt.xticks(rotation=90)  # Rotate sample labels for better readability\n",
    "\n",
    "# Ensure all 58 mRNA labels appear on the y-axis\n",
    "ax.set_yticks(np.arange(df_t_log.shape[0]) + 0.5)  # Center y-ticks\n",
    "ax.set_yticklabels(df_t_log.index, fontsize=10, rotation=0)  # Show all mRNA names\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent label cutoff\n",
    "plt.savefig(\"heatmap_light_palette.jpg\", dpi=600,format=\"jpg\", bbox_inches=\"tight\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7215719c-288c-4bd3-b250-b3f52a5ab019",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
